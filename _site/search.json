[
  {
    "objectID": "info_d.html",
    "href": "info_d.html",
    "title": "Defining General, Hypothetical Interventions",
    "section": "",
    "text": "\\[\n\\renewcommand{\\P}{\\mathsf{P}}\n\\newcommand{\\m}{\\mathsf{m}}\n\\newcommand{\\p}{\\mathsf{p}}\n\\newcommand{\\q}{\\mathsf{q}}\n\\newcommand{\\bb}{\\mathsf{b}}\n\\newcommand{\\g}{\\mathsf{g}}\n\\newcommand{\\rr}{\\mathsf{r}}\n\\newcommand{\\IF}{\\mathbb{IF}}\n\\newcommand{\\dd}{\\mathsf{d}}\n\\newcommand{\\Pn}{$\\mathsf{P}_n$}\n\\newcommand{\\E}{\\mathsf{E}}\n\\]\n\nHow many times have you started to read a paper for a new method in the causal inference literature that contains the sentence ‚Äúassume the treatment or exposure is binary‚Ä¶‚Äù?\n\n\n\n\n\nWell not anymore ü•≥. Assume \\(A\\) is a binary, categorical, or continuous variable! Let \\(\\dd(a, w, \\epsilon)\\) be a function that maps \\(A\\), \\(W\\), and potentially a randomizer \\(\\epsilon\\) to a new value of \\(A\\). We will often refer to the function \\(\\dd\\) as a shift function.\nOur focus in this workshop is estimating the causal effect of an intervention \\(d\\) on the outcome \\(Y\\), through the causal parameter\n\\[\n\\theta = \\E[Y(\\bar A^{\\dd})]\\text{,}\n\\]\nwhere \\(Y(\\bar A^\\dd)\\) is the counterfactual outcome in a world, where possibly contrary to fact, each entry of \\(\\bar{A}\\) was modified according to the function \\(\\dd\\). When \\(Y\\) is continuous, \\(\\theta\\) is the mean population value of \\(Y\\) under intervention \\(\\dd\\); when \\(Y\\) is dichotomous, \\(\\theta\\) is the population proportion of event \\(Y\\) under intervention \\(\\dd\\). Similarly, when \\(Y\\) is the indicator of an event by end of the study, \\(\\theta\\) is defined as the cumulative incidence of \\(Y\\) under intervention \\(\\dd\\).\n\nIdentification of the causal parameter\n\n\n\n\n\n\nAssumptions\n\n\n\n\nPositivity. If \\((a_t, h_t) \\in \\text{supp}\\{A_t, H_t\\}\\) then \\(\\dd(a_t, h_t) \\in \\text{supp}\\{A_t, H_t\\}\\) for \\(t \\in \\{1, ..., \\tau\\}\\).\n\nIf there is a unit with observed treatment value \\(a_t\\) and covariates \\(h_t\\), there must also be a unit with treatment value \\(\\dd(a_t, h_t)\\) and covariates \\(h_t\\).\n\nExchangeability. \\(A_t \\perp \\!\\!\\! \\perp Y(\\bar{a}) | H_t\\) for all \\(\\bar{a} \\in \\mathop{\\mathrm{supp}}\\bar{A}\\) and \\(t \\in \\{1, ..., \\tau\\}\\).\nConsistency. \\(\\bar{A} = \\bar{a} \\implies Y = Y(\\bar{a})\\) for all \\(\\bar{a} \\in \\mathop{\\mathrm{supp}}\\bar{A}\\).\n\n\n\nAssuming ‚Ä¶, \\(\\theta\\) is identified from the observed data by:\n\n\n\n\n\n\nTheorem\n\n\n\nSet \\(\\m_{\\tau+1} = Y\\)&gt; For \\(t = \\tau, ..., 1\\), recursively define\n\\[\n\\m_t: (a_t, h_t) \\rightarrow \\E[\\m_{t + 1}(A^{\\dd}_{t+1}, H_{t + 1}) \\mid A_t = a_t, H_t = h_t],\n\\]\nand define \\(\\theta = E[\\m_1(A^{\\dd}_1, L_1)]\\).\n\n\nAs an example, set \\(\\tau = 2\\). Then we have\n\\[\\begin{align} \\m_3(A_3^d, H_3) &= Y   \\\\  \\m_2(A_2^d, H_2) &= \\E\\left[\\m_3(A_3^d, H_3)\\mid(A_2^d, H_2)\\right] \\\\\\m_1(A_1^d, L_1) &= \\E\\left[\\m_2(A_2^d, H_2)\\mid(A_1^d, L_1)\\right] \\\\\\theta &= \\E\\left[\\m_1(A_1^d, L_1)\\right]\n\n\\end{align}\\]\n\n\nStatic Interventions\nLet \\(A\\) denote a binary vector, such as receiving a medication, and define \\(\\dd_t(a_t, h_t, \\epsilon) = 1\\). This intervention characterizes a hypothetical world where all members of the population receive treatment.\n\n\n\n\n\n\nStatic intervention\n\n\n\nAn intervention is static if the function \\(\\dd_t\\) always returns the same value regardless of the input.\n\n\n\n\nDynamic Treatment Regime\nLet \\(A_t\\) denote a binary vector, such as receiving a medication, and \\(H_t\\) a numeric vector, such as a measure of discomfort. For a given value of \\(\\delta\\), define \\[\n\\dd_t(a_t, h_t, \\epsilon) = \\begin{cases}\n1 &\\text{ if } h_t &gt; \\delta \\\\\n0 &\\text{ otherwise.}\n\\end{cases}\n\\]\n\n\n\n\n\n\nDynamic treatment regime\n\n\n\nInterventions where the output of the function \\(\\dd_t\\) depends only on the covariates \\(H_t\\) are referred to as being dynamic.\n\n\n\n\n\n\n\n\nExample\n\n\n\nRudolph, Williams, et al. (2022) examined a Buprenorphine (BUP-NX) dosing strategy among a population of patients who were taking BUP-NX for opioid use disorder. Under the hypothetical intervention, patients who reported opioid use during the week prior to a physicians exam received a BUP-NX dose increase while patients who did not report prior-week opioid use maintained the same dose. Let \\(A_t\\) be a binary indicator for BUP-NX dose increase at week \\(t\\) compared to week \\(t-1\\) and \\(X_t\\) be an indicator for opioid use at week \\(t\\). Then,\n\\[\n\\dd(a_t, h_t, \\epsilon) = \\begin{cases}\n1 \\text{ if } x_{t-1} = 1\\\\\n0 \\text{ otherwise}\n\\end{cases}\n\\]\n\n\n\n\nTreatment Initiation with Grace Period\n\n\nModified Treatment Policies\nExplain why MTPs are useful:\n\nhelp with positiivty violations\nhelp characterize realistic interventions\nassess interventions you could never run an RCT for\n\n\n\n\n\n\n\nModified treatment policy\n\n\n\nAn intervention characterized by a hypothetical world where the natural value of treatment is modified is called a modified treatment policy.\n\n\n\nAdditive and multiplicative shift MTP\nLet \\(A_t\\) denote a numeric vector. Assume that \\(A_t\\) has support in the data such that \\(P(A_t \\leq u(h_t) \\mid H_t = h_t) = 1\\). For a value of \\(\\delta\\), define \\[\n\\dd(a_t, h_t, \\epsilon) = \\begin{cases}\na_t + \\delta &\\text{ if } a_t + \\delta \\leq u(h_t) \\\\\na_t &\\text{ otherwise.}\n\\end{cases}\n\\]\nUnder this intervention, the natural value of exposure at time \\(t\\) is increased by the analyst-defined value \\(\\delta\\), whenever such an increase is feasible. This MTP is referred to as an additive shift MTP.\n\n\n\n\n\n\nExample\n\n\n\n\n\n\nWe can similarly define a multiplicative shift MTP as\n\\[\n\\dd_t(a_t, h_t, \\epsilon) = \\begin{cases}\na_t \\times \\delta &\\text{ if } a_t \\times \\delta \\leq u(h_t) \\\\\na_t &\\text{ otherwise}.\n\\end{cases}\n\\]\n\n\n\n\n\n\nExample\n\n\n\nNugent and Balzer (2023) evaluated the association between county-level measures of mobility and incident COVID-19 cases in the United States in the Summer and Fall of 2022. They considered both hypothetical additive and multiplicative MTPs; for example, they defined a multiplicative MTP where a measure for the density of mobile devices visiting commercial locations was decreased by 25%:\n\\[\n\\dd_t(a_t, h_t, \\epsilon) = a_t \\times 0.75.\n\\]\n\n\n\n\nThreshold MTP\n\n\n\nStochastic Interventions\n\nRandomized Interventions\n\n\nIncremental Propensity Score Interventions\nLet \\(A\\) denote a binary vector, \\(\\epsilon \\sim U(0, 1)\\), and \\(\\delta\\) be an analyst-defined risk ratio limited to be between \\(0\\) and \\(1\\). If we were interested in an intervention that decreased the likelihood of receiving treatment, define\n\\[\n\\dd_t(a_t, h_t, \\epsilon_t) = \\begin{cases}\na_t &\\text{ if } \\epsilon_t &lt; \\delta \\\\\n0 &\\text{ otherwise.}\n\\end{cases}\n\\]In this case, we have \\(\\g^\\dd(a_t \\mid H_t) = a_t \\delta \\g_t(1 \\mid H_t) + (1 - a_t) (1 - \\delta \\g_t(1\\mid H_t))\\), which leads to a risk ratio of \\(\\g_t^\\dd(1 \\mid H_t)/\\g_t(1\\mid H_t) = \\delta\\) for comparing the propensity score post- vs pre-intervention. Conversely, if we were interested in an intervention that increased the likelihood of receiving treatment, define\n\\[\n\\dd_t(a_t, h_t, \\epsilon_t) = \\begin{cases}\na_t &\\text{ if } \\epsilon_t &lt; \\delta \\\\\n1 &\\text{ otherwise.}\n\\end{cases}\n\\]\nNow \\(\\g_t^\\dd(a_t \\mid H_t) = a_t (1 - \\delta \\g_t(0\\mid H_t)) + (1 - a_t) \\delta \\g_t(0 \\mid H_t)\\), which implies a risk ratio \\(\\g_t^\\dd(0\\mid H_t)/\\g(0\\mid H_t) = \\delta\\).\n\n\n\n\n\n\nIncremental propensity score intervention\n\n\n\nAn intervention where the conditional probability of treatment is shifted.\n\n\n\n\n\n\n\n\nExample\n\n\n\nUsing electronic health record data, Wen, Marcus, and Young (2023) estimated the effect of increasing the proportion of PrEP uptake on bacterial STI among cis-gender males being tested for STIs and that do not have HIV. Let \\(A_t\\) be a binary indicator for PrEP initiation at week \\(t\\), and \\(L'_t\\) be a binary indicator for any STI testing and being HIV-free at week \\(t\\). They defined a ‚Äúmedium‚Äù successful PrEP uptake intervention as\n\\[\n\\dd(a_t, h_t, \\epsilon) = \\begin{cases}\na_t &\\text{ if } l'_t = 1 \\text{ and } \\epsilon_t &lt; 0.85 \\\\\n1 &\\text{ otherwise}.\n\\end{cases}\n\\]\n\n\n\n\n\n\n\n\n\n\n\nChoosing a policy\n\nDƒ±ÃÅaz, Iv√°n, Katherine L Hoffman, and Nima S Hejazi. 2024. ‚ÄúCausal Survival Analysis Under Competing Risks Using Longitudinal Modified Treatment Policies.‚Äù Lifetime Data Analysis 30 (1): 213‚Äì36.\n\n\nDƒ±ÃÅaz, Iv√°n, Nicholas Williams, Katherine L Hoffman, and Edward J Schenck. 2023. ‚ÄúNonparametric Causal Effects Based on Longitudinal Modified Treatment Policies.‚Äù Journal of the American Statistical Association 118 (542): 846‚Äì57.\n\n\nHaneuse, Sebastian, and Andrea Rotnitzky. 2013. ‚ÄúEstimation of the Effect of Interventions That Modify the Received Treatment.‚Äù Statistics in Medicine 32 (30): 5260‚Äì77.\n\n\nKennedy, Edward H. 2019. ‚ÄúNonparametric Causal Effects Based on Incremental Propensity Score Interventions.‚Äù Journal of the American Statistical Association 114 (526): 645‚Äì56.\n\n\nNugent, Joshua R, and Laura B Balzer. 2023. ‚ÄúA Demonstration of Modified Treatment Policies to Evaluate Shifts in Mobility and COVID-19 Case Rates in US Counties.‚Äù American Journal of Epidemiology 192 (5): 762‚Äì71.\n\n\nRudolph, Kara E, Catherine Gimbrone, Ellicott C Matthay, Ivan Diaz, Corey S Davis, Katherine Keyes, and Magdalena Cerd√°. 2022. ‚ÄúWhen Effects Cannot Be Estimated: Redefining Estimands to Understand the Effects of Naloxone Access Laws.‚Äù Epidemiology 33 (5): 689‚Äì98.\n\n\nRudolph, Kara E, Nicholas T Williams, Alicia T Singham Goodwin, Matisyahu Shulman, Marc Fishman, Iv√°n Dƒ±ÃÅaz, Sean Luo, John Rotrosen, and Edward V Nunes. 2022. ‚ÄúBuprenorphine & Methadone Dosing Strategies to Reduce Risk of Relapse in the Treatment of Opioid Use Disorder.‚Äù Drug and Alcohol Dependence 239: 109609.\n\n\nWen, Lan, Julia L Marcus, and Jessica G Young. 2023. ‚ÄúIntervention Treatment Distributions That Depend on the Observed Treatment Process and Model Double Robustness in Causal Survival Analysis.‚Äù Statistical Methods in Medical Research 32 (3): 509‚Äì23.",
    "crumbs": [
      "Home",
      "2. Defining Interventions"
    ]
  },
  {
    "objectID": "R_survival.html",
    "href": "R_survival.html",
    "title": "Survival Analysis",
    "section": "",
    "text": "\\[\n\\renewcommand{\\P}{\\mathsf{P}}\n\\newcommand{\\m}{\\mathsf{m}}\n\\newcommand{\\p}{\\mathsf{p}}\n\\newcommand{\\q}{\\mathsf{q}}\n\\newcommand{\\bb}{\\mathsf{b}}\n\\newcommand{\\g}{\\mathsf{g}}\n\\newcommand{\\rr}{\\mathsf{r}}\n\\newcommand{\\IF}{\\mathbb{IF}}\n\\newcommand{\\dd}{\\mathsf{d}}\n\\newcommand{\\Pn}{$\\mathsf{P}_n$}\n\\newcommand{\\E}{\\mathsf{E}}\n\\]\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nData structure\n\nSimilar to when the outcome is binary, survival outcomes should be coded using zero‚Äôs and one‚Äôs where one indicates the occurrence of an event and zero otherwise.\nSimilar to how we encode censoring variables, we consider the outcome to be degenerate. Meaning that once an observation experiences an outcome, all future outcome variables should also be coded with a one.\n\n\n\n\nStructure of data with survival outcome and point-treatment. Adapted from Hoffman et al., 2022.\n\n\n\n\n\nStructure of data with survival outcome and time-varying treatment. Adapted from Hoffman et al., 2022.\n\n\n\n\nExample: Point-treatment\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\nExample: Time-varying treatment: Delaying invasive mechanical ventilation\nHoffman et al. (2023) demonstrated the use of modified treatment policies for survival outcomes to assess the effect of delaying invasive mechanical ventilation (IMV) on mortality among patients hospitalized with COVID-19 in New York City during the first COVID-19 wave. A synthetic version of the data used for that analysis has been loaded into R as intubation.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nThe data consists of \\(n = 2000\\) observations hospitalized with COVID-19 and who were followed for \\(\\tau = 14\\) days. There are 10 baseline confounders and 4 time-varying confounders. The outcome of interest is an indicator for death on day \\(t\\). Observations are subject to loss-to-follow-up due to either hospital discharge or transfer.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nFormally, let‚Äôs consider the following intervention\n\\[\n\\dd_t(a_t, h_t) = \\begin{cases}\n1 \\text{ if } a_t = 2 \\text{ and } a_s \\leq 1 \\forall s &lt; t \\\\\na_t \\text{ otherwise},\n\\end{cases}\n\\]\nwhere \\(A_t\\) is a 3-level categorical variable: 0, no supplemental oxygen; 1, non-IMV supplemental oxygen support; 2, IMV.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nIn words, this function corresponds to an intervention where patients who were naturally observed as receiving IMV on day \\(t\\) instead had IMV delayed by a day to day \\(t+1\\). Let‚Äôs translate this policy to an R function that we can use with lmtp.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\n\n\nQuestion\n\n\n\nWhy might defining an intervention in terms of an MTP instead of a static intervention be more useful to answer a question about the effect of IMV on death among patients hospitalized with COVID-19?\n\n\nAnswer\n\n\n\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\n\nReferences\n\nHoffman, Katherine L, Diego Salazar-Barreto, Kara E Rudolph, and Iv√°n Dƒ±ÃÅaz. 2023. ‚ÄúIntroducing Longitudinal Modified Treatment Policies: A Unified Framework for Studying Complex Exposures.‚Äù arXiv Preprint arXiv:2304.09460.",
    "crumbs": [
      "Home",
      "4. Estimating Effects with lmtp",
      "Survival Analysis"
    ]
  },
  {
    "objectID": "info_estimators.html",
    "href": "info_estimators.html",
    "title": "Estimators",
    "section": "",
    "text": "\\[\n\\renewcommand{\\P}{\\mathsf{P}}\n\\newcommand{\\m}{\\mathsf{m}}\n\\newcommand{\\p}{\\mathsf{p}}\n\\newcommand{\\q}{\\mathsf{q}}\n\\newcommand{\\bb}{\\mathsf{b}}\n\\newcommand{\\g}{\\mathsf{g}}\n\\newcommand{\\rr}{\\mathsf{r}}\n\\newcommand{\\IF}{\\mathbb{IF}}\n\\newcommand{\\dd}{\\mathsf{d}}\n\\newcommand{\\Pn}{$\\mathsf{P}_n$}\n\\newcommand{\\E}{\\mathsf{E}}\n\\]\n\nTo recap, we‚Äôve\n\ndefined a causal parameter \\(\\theta\\) that is a function of a general hypothetical intervention, \\(\\dd_t(a_t, h_t, \\epsilon)\\), and\ndefined the necessary assumptions to identify the expected value of \\(Y\\) when \\(A\\) is replaced with the output of \\(\\dd_t(a_t, h_t, \\epsilon)\\) from observed data.\n\nIt‚Äôs now time to discussing how to estimate these parameters.\n\nSequential Regression Estimator\nOne possible estimator is simply a plug-in estimator of the identification result. This estimator is often referred to as G-computation.\n\n\nAlgorithm: Sequential regressions\n\n\n\nSet \\(\\m_{i,\\tau +1} = Y_i\\).\nFor \\(t = \\tau, ..., 1\\):\n\nUsing a pre-specified parametric model, regress \\(\\m_{i,t+1}\\) on \\(\\{A_{i, t}, H_{i,t}\\}\\).\nGenerate predictions from this model with \\(A_{i,t}\\) changed to \\(A^{\\dd}_{i,t}\\). Set \\(\\m_{i, t}\\) as these predictions.\n\nTake the final estimate as \\(\\hat{\\theta} = \\frac{1}{n}\\sum_{i=1}^n \\m_{i, 1}\\).\nCompute standard errors using a bootstrap of steps 1 and 2.\n\n\n\n\n\n\n\n\n\n\nPros ‚úÖ\nCons ‚ùå\n\n\n\n\n\nSimple to implement\n\n\nRequires correct estimation of all regressions\nRequires pre-specified parametric models\n\n\n\n\n\n\nDensity-ratio estimation\nThe following three estimators all rely on estimating the density ratio \\(r_t(a_t, h_t) = \\frac{\\g_t^\\dd(a_t \\mid h_t)}{\\g_t(a_t \\mid h_t)}\\). We will often refer to this ratio as the intervention mechanism throughout the workshop.\n\nWe can directly estimate this density ratio with a classification trick. This process is fully automated and hidden from the user.\nCan compute the odds in a classification problem in an augmented dataset with \\(2n\\) observations where the outcome is the auxiliary variable \\(\\Lambda\\) (defined below) and the predictors are the variables \\(A_t\\) and \\(H_t\\). In the \\(2n\\) augmented data set, the data structure at time \\(t\\) is redefined as\n\n\\[\n(H_{\\lambda, i, t}, A_{\\lambda, i, t}, \\Lambda_{\\lambda, i} : \\lambda = 0, 1; i = 1, ..., n)\n\\]\n\n\\(\\Lambda_{\\lambda, i} = \\lambda_i\\) indexes duplicate values\n\nFor all duplicated observations \\(\\lambda\\in\\{0,1\\}\\) with the same \\(i\\), \\(H_{\\lambda, i, t}\\) is the same\nFor \\(\\lambda = 0\\), \\(A_{\\lambda, i, t}\\) equals the observed exposure values \\(A_{i, t}\\)\nFor \\(\\lambda=1\\), \\(A_{\\lambda, i, t}\\) equals the exposure values under the intervention \\(\\dd\\), \\(A^{\\dd}_t\\)\n\nThe classification approach to density ratio estimation proceeds by estimating the conditional probability that \\(\\Delta=1\\) in this dataset, and dividing it by the corresponding estimate of the conditional probability that \\(\\Delta=0\\). Specifically, denoting \\(p^\\lambda\\) the distribution of the data in the augmented dataset, we have:\n\n\\[\nr_t(a_t, h_t) = \\frac{p^\\lambda(a_t, h_t \\mid \\Lambda =\n    1)}{p^\\lambda(a_t, h_t \\mid \\Lambda =\n    0)}=\\frac{p^\\lambda(\\Lambda = 1\\mid A_t=a_t,\n    H_t=h_t)}{p^\\lambda(\\Lambda = 0\\mid A_t=a_t, H_t=h_t)}\n\\]\n\n\nInverse Probability Weighting\n\\[\n\\theta = \\E \\bigg[ \\bigg\\{\\prod_{t=1}^\\tau r_t(a_t, h_t) \\bigg\\} Y \\bigg]\n\\]\n\n\nAlgorithm: IPW Estimator\n\n\n\nConstruct estimates of \\(r_{i,t}(a_t, h_t)\\) using the density ratio classification trick and a pre-specified parametric model.\nDefine the weights \\(w_{i} = \\prod_{t=1}^\\tau r_{i,t}(a_t, h_t)\\).\nTake the final estimate as \\(\\hat{\\theta} = \\frac{1}{n}\\sum_{i=1}^n w_{i}\\times y_i\\).\nCompute standard errors using a bootstrap of steps 1-3.\n\n\n\n\n\n\n\n\n\n\nPros ‚úÖ\nCons ‚ùå\n\n\n\n\n\nSimple to implement\n\n\nRequires correct estimation of density ratios\nRequires pre-specified parametric models\n\n\n\n\n\n\nDoubly Robust Estimators\nG-computation and IPW estimators require the estimation of nuisance parameters with parametric models. We will now turn our attention to two non-parametric estimators:\n\ntargeted minimum-loss based estimator (TMLE), and\na sequentially doubly-robust estimator (SDR).\n\n\nEfficient Influence Function\nKey to constructing the TMLE and SDR is the efficient influence function (EIF).\n\nThe EIF characterizes the asymptotic behavior of all regular and efficient estimators.\nThe EIF characterizes the first-order bias of pathwise differentiable estimands.\n\nBefore we introduce the EIF, it‚Äôs necessary to make some additional assumptions on \\(A\\) and \\(\\dd\\).\n\n\n\n\n\n\nAssumptions\n\n\n\n\nThe treatment \\(A\\) is discrete, or\nIf \\(A\\) is continuous, the function \\(\\dd\\) is piecewise smooth invertible\nThe function \\(\\dd\\) does not depend on the observed distribution \\(\\P\\)\n\n\n\n\nThese assumptions ensure that the efficient influence function of \\(\\theta\\) for interventions \\(\\dd\\) have a structure similar to the influence function for the effect of dynamic regimes.\nThis allows for multiply robust estimation, which is not generally possible for interventions \\(\\dd\\) that depend on \\(\\P\\).\n\nDefine the function\n\\[\n\\phi_t: O \\mapsto \\sum_{s=t}^\\tau \\bigg( \\prod_{k=t}^s r_k(a_k, h_k)\\bigg) \\big\\{\\m_{s+1}(a_{s+1}^\\dd, h_{s+1}) - \\m_s(a_s, h_s) \\big\\} + \\m_t(a_t^\\dd, h_t).\n\\]\nThe efficient influence function for estimating \\(\\theta = \\E[\\m_1(A^\\dd, L_1)]\\) in the non-parametric model is given by \\(\\phi_1(O) - \\theta\\). In the case of single time-point, the influence function simplifies to\n\\[\nr(a, w)\\{Y - \\m(a,w)\\} + \\m(a^{\\dd},w) - \\theta.\n\\]\n\n\nTargeted Minimum-Loss Based Estimation\n\n\nAlgorithm: TMLE\n\n\n\nConstruct estimates of \\(r_{i,t}(a_t, h_t)\\) using the density ratio classification trick and your favorite regression method.\nFor \\(s = 1, ..., \\tau\\), compute the weights: \\(w_{i,s} = \\prod_{k=1}^s r_{i,k}(a_{i,k}, h_{i,k})\\)\nSet \\(\\tilde{\\m}_{i,\\tau +1}(A^\\dd_{i,t+1}, H_{i,t+1}) = Y_i\\).\nFor \\(t = \\tau, ..., 1\\):\n\nRegress \\(\\tilde{\\m}_{i,t+1}(A^\\dd_{i,t+1}, H_{i,t+1})\\) on \\(\\{A_{i, t}, H_{i,t}\\}\\).\nFit the generalized linear tilting model:\n\\(\\text{link }\\tilde{\\m}^\\epsilon_t(A_{i,t}, H_{i,t}) = \\epsilon + \\text{link }\\tilde{\\m}_t(A_{i,t}, H_{i,t})\\)\nwith weights \\(w_{i,t}\\).\nLet \\(\\hat\\epsilon\\) be the maximum likelihood estimate, and update the estimates as:\n\\(\\text{link }\\tilde{\\m}^\\hat\\epsilon_t(A^\\dd_{i,t}, H_{i,t}) = \\epsilon + \\text{link }\\tilde{\\m}_t(A^\\dd_{i,t}, H_{i,t})\\)\n\\(\\text{link }\\tilde{\\m}^\\hat\\epsilon_t(A_{i,t}, H_{i,t}) = \\epsilon + \\text{link }\\tilde{\\m}_t(A_{i,t}, H_{i,t})\\)\nUpdate \\(\\tilde{\\m}_{i,t} = \\tilde{\\m}^\\hat\\epsilon_{i,t}\\), \\(t = t-1\\), and iterate.\n\nThe final estimate is defined as \\(\\hat\\theta = \\frac{1}{n}\\sum_{i=1}^n\\tilde{m}_{i, 1}(A^\\dd_{i, 1}, L_{i, 1})\\).\n\n\n\n\n\n\n\n\n\n\nPros ‚úÖ\nCons ‚ùå\n\n\n\n\n\nSubstitution estimator\ndoubly-robust\ncan use machine learning\n\n\nnot sequentially doubly-robust\n\n\n\n\n\n\nSequentially Doubly Robust Estimator\n\n\nAlgorithm: SDR Estimator\n\n\n\nConstruct estimates of \\(r_{i,t}(a_t, h_t)\\) using the density ratio classification trick and your favorite regression method.\nInitialize \\(\\phi_{\\tau +1}(O_i) = Y_i\\).\nFor \\(t = \\tau, ..., 1\\):\n\nCompute the pseudo-outcome \\(\\check{Y}_{i,t+1} = \\phi_{t+1}(O_i)\\).\nRegress \\(\\check{Y}_{i,t+1}\\) on \\(\\{A_{i, t}, H_{i,t}\\}\\).\nLet \\(\\check\\m_{i,t}\\) denote the output. Update \\(\\m_{i,t} = \\check\\m_{i,t}\\) and iterate.\n\nThe final estimate is defined as \\(\\hat\\theta = \\frac{1}{n}\\sum_{i=1}^n\\phi_1(O_i).\\)\n\n\n\n\n\n\n\n\n\n\nPros ‚úÖ\nCons ‚ùå\n\n\n\n\n\ndoubly-robust\nsequentially doubly-robust\ncan use machine learning\n\n\nnot a substitution estimator\n\n\n\n\n\n\n\nChoosing an Estimator\nHow should we choose which estimator to use?\n\nIn general we never recommend using the IPW or sequential regression estimator. Both require the use of correctly pre-specified parametric models for valid statistical inference (ya right üòÇ).\nThe TMLE and SDR estimators, however, are both doubly or sequentially doubly robust and can be used with machine-learning algorithms while remaining \\(\\sqrt{n}\\)-consistent.\n\nWait, what does it mean for an estimator to be doubly robust?\n\nFor the simple case of a single time point, an estimator is considered doubly robust if it is able to produce a consistent estimate of the target parameter as long as at least one of the nuisance parameters is consistently estimated.\nFor time-varying setting, an estimator is doubly robust if, for some time \\(s\\), all outcome regressions for \\(t &gt;s\\) are consistently estimated and all intervention mechanisms for \\(t \\leq s\\) are consistently estimated.\nSequential double robustness (often also referred to as \\(2^\\tau\\)-multiply robust) implies that an estimator is consistent if for all times either the outcome or intervention mechanism is consistently estimated.\n\nWhile the SDR estimator may be more robust to model misspecification, the TMLE does have the advantage of being a substitution estimator. Because of this, estimates from the TMLE are guaranteed to stay within the valid range of the outcome. Taken together, this leads to the following recommendations for choosing between the TMLE and SDR:\n\n\n\n\n\n\n\nIf treatment is not time-varying, use the TMLE.\nIf treatment is time-varying first try the SDR.\nIf the SDR estimator produces ‚Äúout-of-bounds‚Äù estimates, instead use the TMLE.\n\n\n\n\n\nTable 1. Summary of estimator properties.\n\n\n\n\n\n\n\n\n\n\nIPW\nG-comp.\nTMLE\nSDR\n\n\n\n\nUses outcome regression\n\n‚≠ê\n‚≠ê\n‚≠ê\n\n\nUses the propensity score\n‚≠ê\n\n‚≠ê\n‚≠ê\n\n\nValid inference with machine-learning\n\n\n‚≠ê\n‚≠ê\n\n\nSubstitution estimator\n\n‚≠ê\n‚≠ê\n\n\n\nDoubly robust\n\n\n‚≠ê\n‚≠ê\n\n\nSequentially doubly robust\n\n\n\n‚≠ê\n\n\n\n\n\nCross-fitting\nWhen estimating nuisance parameters with data adaptive algorithms, you should perform a process similar to cross-validation called cross-fitting. Cross-fitting ensures:\n\nthat standard errors will be correct, and\ncan help reduce estimator bias.\n\nCross-fitting is fully automated in lmtp, but for more information we recommend reviewing Chernozhukov et al. (2018), Dƒ±ÃÅaz (2020), and Zivich and Breskin (2021).\n\n\n\n\n\nReferences\n\nBickel, Peter J, Chris AJ Klaassen, Peter J Bickel, Ya‚Äôacov Ritov, J Klaassen, Jon A Wellner, and YA‚ÄôAcov Ritov. 1993. Efficient and Adaptive Estimation for Semiparametric Models. Vol. 4. Springer.\n\n\nChernozhukov, Victor, Denis Chetverikov, Mert Demirer, Esther Duflo, Christian Hansen, Whitney Newey, and James Robins. 2018. ‚ÄúDouble/Debiased Machine Learning for Treatment and Structural Parameters.‚Äù Oxford University Press Oxford, UK.\n\n\nDƒ±ÃÅaz, Iv√°n. 2020. ‚ÄúMachine Learning in the Estimation of Causal Effects: Targeted Minimum Loss-Based Estimation and Double/Debiased Machine Learning.‚Äù Biostatistics 21 (2): 353‚Äì58.\n\n\nDƒ±ÃÅaz, Iv√°n, Nicholas Williams, Katherine L Hoffman, and Edward J Schenck. 2023. ‚ÄúNonparametric Causal Effects Based on Longitudinal Modified Treatment Policies.‚Äù Journal of the American Statistical Association 118 (542): 846‚Äì57.\n\n\nHaneuse, Sebastian, and Andrea Rotnitzky. 2013. ‚ÄúEstimation of the Effect of Interventions That Modify the Received Treatment.‚Äù Statistics in Medicine 32 (30): 5260‚Äì77.\n\n\nHoffman, Katherine L, Diego Salazar-Barreto, Kara E Rudolph, and Iv√°n Dƒ±ÃÅaz. 2023. ‚ÄúIntroducing Longitudinal Modified Treatment Policies: A Unified Framework for Studying Complex Exposures.‚Äù arXiv Preprint arXiv:2304.09460.\n\n\nKennedy, Edward H. 2019. ‚ÄúNonparametric Causal Effects Based on Incremental Propensity Score Interventions.‚Äù Journal of the American Statistical Association 114 (526): 645‚Äì56.\n\n\nZivich, Paul N, and Alexander Breskin. 2021. ‚ÄúMachine Learning for Causal Inference: On the Use of Cross-Fit Estimators.‚Äù Epidemiology 32 (3): 393‚Äì401.",
    "crumbs": [
      "Home",
      "3. Estimators"
    ]
  },
  {
    "objectID": "R_advanced.html",
    "href": "R_advanced.html",
    "title": "Beyond the \n Average Treatment Effect",
    "section": "",
    "text": "https://ehjournal.biomedcentral.com/articles/10.1186/s12940-019-0482-6"
  },
  {
    "objectID": "instructors.html",
    "href": "instructors.html",
    "title": "Instructors",
    "section": "",
    "text": "Nick Williams\nNick is a Senior Data Analyst in Columbia University‚Äôs Mailman School of Publich Health, Department of Epidemiology. His interests are in the development of statistical computing tools for novel causal inference methods. He‚Äôs the author and maintainer of multiple R packages.\n\n\n\nKara Rudolph\nKara is an Assistant Professor of Epidemiology at Columbia University, Mailman School of Public Health. Her research interests are in developing and applying causal inference methods to understand social and contextual influences on mental health, substance use, and violence. Her current work focuses on developing and applying methods for transportability and mediations to understand mechanisms relevant for drug use disorder prevention and treatment in various target populations.\n\n\n\nIv√°n D√≠az\nIv√°n is an Associate Professor of Biostatistics at New York University Grossman School of Medicine. His research focuses on the development of non-parametric statistical methods for causal inference from observational and randomized studies with complex datasets, using machine learning. This includes but is not limited to mediation analysis, methods for continuous exposures, longitudinal data including survival analysis, and efficiency guarantees with covariate adjustment in randomized trials."
  },
  {
    "objectID": "R_stochastic.html",
    "href": "R_stochastic.html",
    "title": "Stochastic Interventions",
    "section": "",
    "text": "Random Interventions\n\n\nIncremental Propensity Score Interventions\nblah blah blah\n\n\n\n\n\nReferences\n\nDƒ±ÃÅaz, Iv√°n, Katherine L Hoffman, and Nima S Hejazi. 2024. ‚ÄúCausal Survival Analysis Under Competing Risks Using Longitudinal Modified Treatment Policies.‚Äù Lifetime Data Analysis 30 (1): 213‚Äì36.\n\n\nDƒ±ÃÅaz, Iv√°n, Nicholas Williams, Katherine L Hoffman, and Edward J Schenck. 2023. ‚ÄúNonparametric Causal Effects Based on Longitudinal Modified Treatment Policies.‚Äù Journal of the American Statistical Association 118 (542): 846‚Äì57.\n\n\nKennedy, Edward H. 2019. ‚ÄúNonparametric Causal Effects Based on Incremental Propensity Score Interventions.‚Äù Journal of the American Statistical Association 114 (526): 645‚Äì56.\n\n\nWen, Lan, Julia L Marcus, and Jessica G Young. 2023. ‚ÄúIntervention Treatment Distributions That Depend on the Observed Treatment Process and Model Double Robustness in Causal Survival Analysis.‚Äù Statistical Methods in Medical Research 32 (3): 509‚Äì23.",
    "crumbs": [
      "Home",
      "4. Estimating Effects with lmtp",
      "Stochastic Interventions"
    ]
  },
  {
    "objectID": "macros.html",
    "href": "macros.html",
    "title": "Beyond the \n Average Treatment Effect",
    "section": "",
    "text": "\\[\n\\renewcommand{\\P}{\\mathsf{P}}\n\\newcommand{\\m}{\\mathsf{m}}\n\\newcommand{\\p}{\\mathsf{p}}\n\\newcommand{\\q}{\\mathsf{q}}\n\\newcommand{\\bb}{\\mathsf{b}}\n\\newcommand{\\g}{\\mathsf{g}}\n\\newcommand{\\rr}{\\mathsf{r}}\n\\newcommand{\\IF}{\\mathbb{IF}}\n\\newcommand{\\dd}{\\mathsf{d}}\n\\newcommand{\\Pn}{$\\mathsf{P}_n$}\n\\newcommand{\\E}{\\mathsf{E}}\n\\]"
  },
  {
    "objectID": "R_multivariate.html",
    "href": "R_multivariate.html",
    "title": "Multivariate exposures",
    "section": "",
    "text": "\\[\n\\renewcommand{\\P}{\\mathsf{P}}\n\\newcommand{\\m}{\\mathsf{m}}\n\\newcommand{\\p}{\\mathsf{p}}\n\\newcommand{\\q}{\\mathsf{q}}\n\\newcommand{\\bb}{\\mathsf{b}}\n\\newcommand{\\g}{\\mathsf{g}}\n\\newcommand{\\rr}{\\mathsf{r}}\n\\newcommand{\\IF}{\\mathbb{IF}}\n\\newcommand{\\dd}{\\mathsf{d}}\n\\newcommand{\\Pn}{$\\mathsf{P}_n$}\n\\newcommand{\\E}{\\mathsf{E}}\n\\]\n\n\n\nlmtp can estimate effects of simultaneous interventions on multiple variables\nPractically, this is useful for assessing the effects of mixtures on environmental outcomes\nWhen intervening on multiple variables, trt should be supplied a list of variable names instead of a vector.\n\n\n\nNIEHS Simulation Data\nFor our example of estimating the effects of simultaneous interventions on multiple variables, we will use simulated data from the 2015 NIEHS Mixtures Workshop. The data has already been loaded into R in the background as mixtures. You can view and download the raw data here.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nThe simulated data has \\(n = 500\\) observations and is intended to replicate a prospective cohort study. The data is composed of 7 log-normally distributed and correlated exposures variables (\"X1\", \"X2\", \"X3\", \"X4\", \"X5\", \"X6\", \"X7\"), a single continuous outcome (\"Y\"), and one binary confounder (\"Z\"). There is no missing covariate data, no measurement error, and no censoring.\n\n\n\n\n\n\n\n\n\nCharacteristic\nN = 5001\n\n\n\n\nY\n21 (14, 32)\n\n\nX1\n0.86 (0.41, 1.49)\n\n\nX2\n0.93 (0.66, 1.29)\n\n\nX3\n0.85 (0.44, 1.56)\n\n\nX4\n0.97 (0.62, 1.54)\n\n\nX5\n0.92 (0.49, 1.68)\n\n\nX6\n0.92 (0.53, 1.59)\n\n\nX7\n0.84 (0.41, 1.51)\n\n\nZ\n214 (43%)\n\n\n\n1 Median (IQR); n (%)\n\n\n\n\n\n\n\n\n\nOnly exposure variables X1, X2, X4, X5, and X7 have an effect on the outcome Y. However, the direction of the effects varies. Variables X1, X2, and X7 are positively associated with the outcome; X4 and X5 are negatively associated with the outcome.\nOnly two things need to change when using lmtp estimators with multivariate treatments:\n\nInstead of a vector, you should now pass a list to the trt argument\nThe shift function should return a named list of vectors instead of a single vector.\n\nLet‚Äôs use lmtp to estimate the effect of a modified treatment policy which intervenes on all 7 exposure simultaneously on the outcome:\n\\[\n\\dd(\\mathbf{a}, h) =\n\\begin{cases} \\dd(a_1, h) =\n\\begin{cases}\na_1 - 0.2 &\\text{ if } a_1 - 0.2 &gt; 0 \\\\\na_1 &\\text{ otherwise }\n\\end{cases} \\\\\n\\dd(a_2, h) =\n\\begin{cases}\na_2 - 0.4 &\\text{ if } a_2 - 0.4 &gt; 0 \\\\\na_2 &\\text{ otherwise }\n\\end{cases} \\\\\n\\dd(a_3, h) = a_3 + 0.4 \\\\\n\\dd(a_4, h) = a_4 + 0.1 \\\\\n\\dd(a_5, h) = a_5 + 0.5 \\\\\n\\dd(a_6, h) =\n\\begin{cases}\na_6 - 0.2 &\\text{ if } a_6 - 0.2 &gt; 0 \\\\\na_6 &\\text{ otherwise }\n\\end{cases} \\\\\n\\dd(a_7, h) =\n\\begin{cases}\na_7 - 0.3 &\\text{ if } a_7 - 0.3 &gt; 0 \\\\\na_7 &\\text{ otherwise }\n\\end{cases}\n\\end{cases}\n\\]\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\nLearning assessment\n\n\n\n\n\n\nProblem 1\n\n\n\nUsing TMLE, estimate the population mean outcome under the simultaneous intervention we just defined. Fit both the treatment mechanism and the outcome regression using this set of learners: c(\"SL.mean\", \"SL.glm\", \"SL.gam\", \"SL.rpart\", \"SL.rpartPrune\", \"SL.step.interaction\"). Assign the result to ans. To save time, don‚Äôt use crossfitting; lmtp has already been loaded into the R session.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\nSolution\n\n\nset.seed(4363754)\n\nlearners &lt;- c(\"SL.mean\", \n              \"SL.glm\", \n              \"SL.gam\", \n              \"SL.rpart\", \n              \"SL.rpartPrune\", \n              \"SL.step.interaction\")\n\nans &lt;- lmtp_tmle(data = mixtures, \n                 trt = A, \n                 outcome = \"Y\", \n                 baseline = \"Z\", \n                 shift = d, \n                 mtp = TRUE,\n                 outcome_type = \"continuous\",\n                 learners_trt = learners, \n                 learners_outcome = learners, \n                 folds = 1)\n\nprint(ans)\n\n\n\n\n\n\n\n\n\n\nProblem 2\n\n\n\nCompared to what was observed under the natural course of exposure, how did intervening upon the set of exposures effect the outcome? Estimate this effect using the lmtp_contrast() function.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\nSolution\n\n\nobs_y &lt;- mean(mixtures$Y)\nlmtp_contrast(ans, ref = obs_y)\n\n\n\n\n\n\nReferences\nTaylor, Kyla W., et al.¬†‚ÄúStatistical approaches for assessing health effects of environmental chemical mixtures in epidemiology: lessons from an innovative workshop.‚Äù Environmental health perspectives 124.12 (2016): A227-A229.",
    "crumbs": [
      "Home",
      "4. Estimating Effects with lmtp",
      "Multivariate Exposures"
    ]
  },
  {
    "objectID": "R_static.html",
    "href": "R_static.html",
    "title": "Static Interventions",
    "section": "",
    "text": "\\[\n\\renewcommand{\\P}{\\mathsf{P}}\n\\newcommand{\\m}{\\mathsf{m}}\n\\newcommand{\\p}{\\mathsf{p}}\n\\newcommand{\\q}{\\mathsf{q}}\n\\newcommand{\\bb}{\\mathsf{b}}\n\\newcommand{\\g}{\\mathsf{g}}\n\\newcommand{\\rr}{\\mathsf{r}}\n\\newcommand{\\IF}{\\mathbb{IF}}\n\\newcommand{\\dd}{\\mathsf{d}}\n\\newcommand{\\Pn}{$\\mathsf{P}_n$}\n\\newcommand{\\E}{\\mathsf{E}}\n\\]\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nMotivating data\nFor our first example, we‚Äôll use a synthetic dataset of \\(n = 1000\\) patients from a hypothetical clinical trial for a treatment to decrease intubation and death among patients hospitalized with COVID-19. The data is based on a database of over 1,500 patients hospitalised at Weill Cornell Medicine New York Presbyterian Hospital prior to 15 May 2020 with COVID-19 confirmed through PCR.\n\nTo replicate a two-arm randomized clinical trial (RCT), we‚Äôve simulated a hypothetical treatment variable (A) that is randomly assigned for each observation with probability 0.5.\nThe outcome of interest (event) is intubation or death by 14-days post-hospitalization; treatment is associated with increased survival.\nBaseline covariates include: age, sex, BMI, smoking status, whether the patient required supplemental oxygen within 3 hours of presenting to the emergency department, number of comorbidities, number of relevant symptoms, presence of bilateral infiltrates on chest X-ray, dyspnea, and hypertension.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\n0, N = 4961\n1, N = 5041\n\n\n\n\nevent\n149 (30%)\n140 (28%)\n\n\nage\n66 (52, 77)\n63 (51, 78)\n\n\nsex\n\n\n\n\n\n\n¬†¬†¬†¬†Female\n210 (42%)\n216 (43%)\n\n\n¬†¬†¬†¬†Male\n286 (58%)\n288 (57%)\n\n\nbmi\n27 (23, 31)\n27 (23, 31)\n\n\nsmoke\n\n\n\n\n\n\n¬†¬†¬†¬†Active Smoker\n31 (6.3%)\n21 (4.2%)\n\n\n¬†¬†¬†¬†Former Smoker\n122 (25%)\n119 (24%)\n\n\n¬†¬†¬†¬†No\n343 (69%)\n364 (72%)\n\n\no2\n222 (45%)\n223 (44%)\n\n\nnum_comorbid\n\n\n\n\n\n\n¬†¬†¬†¬†0\n115 (23%)\n121 (24%)\n\n\n¬†¬†¬†¬†1\n118 (24%)\n113 (22%)\n\n\n¬†¬†¬†¬†2\n93 (19%)\n97 (19%)\n\n\n¬†¬†¬†¬†3\n86 (17%)\n78 (15%)\n\n\n¬†¬†¬†¬†4\n40 (8.1%)\n55 (11%)\n\n\n¬†¬†¬†¬†5\n20 (4.0%)\n24 (4.8%)\n\n\n¬†¬†¬†¬†6\n14 (2.8%)\n12 (2.4%)\n\n\n¬†¬†¬†¬†7\n8 (1.6%)\n4 (0.8%)\n\n\n¬†¬†¬†¬†8\n2 (0.4%)\n0 (0%)\n\n\nnum_symptoms\n3 (2, 4)\n4 (2, 5)\n\n\nbilat\n335 (68%)\n332 (66%)\n\n\ndyspnea\n296 (60%)\n303 (60%)\n\n\nhyper\n296 (60%)\n296 (59%)\n\n\n\n1 n (%); Median (IQR)\n\n\n\n\n\n\n\n\n\n\n\nPopulation mean outcomes\nOur goal is to estimate the average treatment effect (ATE) of the hypothetical treatment on intubation or death:\n\\[\n\\begin{align}\n\\theta &= \\E(Y^{A=1} - Y^{A=0}) \\\\\n&= \\textcolor{blue}{\\E(Y^{A=1})} - \\textcolor{red}{\\E(Y^{A=0})}\n\\end{align}\n\\]\nNotice that the ATE is composed of two parameters:\n\nthe proportion of patients who receive intubation or die in a hypothetical world where all patients receive treatment (\\(\\textcolor{blue}{\\E(Y^{A=1})}\\)), and\nthe proportion of patients who receive intubation or die in a hypothetical world where no patients receive treatment (\\(\\textcolor{red}{\\E(Y^{A=0})}\\)).\n\nWe refer to these parameters as population mean outcomes. Let‚Äôs rewrite the target parameter as a function of interventions using the framework we previously discussed. Let \\(\\dd_1(a, h) = 1\\) and \\(\\dd_0(a, h) = 0\\). Then,\n\\[\n\\theta = \\textcolor{blue}{\\E(Y^{\\dd_1})} - \\textcolor{red}{\\E(Y^{\\dd_0})}.\n\\]\nRemember, we refer to these interventions as static because they return the same value regardless of their input.\n\nWriting shift functions\nSo, how do we translate the functions \\(\\dd_1\\) and \\(\\dd_0\\) into R code to be used with lmtp?\n\n\n\n\n\n\nPolicies can be specified using one of two arguments in lmtp estimators: shift or shifted.\n\n\n\nIf using shift, we supply a two-argument function of the form\n\nd &lt;- function(data, trt) {\n  # Insert code here\n}\n\n\nThe first argument should correspond to a dataset containing all the variables in \\(O\\).\nThe second argument should expect a string corresponding to the variable(s) \\(A_t\\) in \\(O\\).\nThis function should return a size \\(n\\) vector with the same class as \\(A_t\\) modified according to \\(d_t\\).\n\nFor \\(\\dd_1\\) this function would be:\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nIf we apply this function to our data we are returned a vector of 1s with the same length as the number of rows in the observed data.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nLet‚Äôs now estimate \\(\\E(Y^{\\dd_1})\\) using lmtp.\n\n\n\n\n\n\nQuestion\n\n\n\nWhich estimator should we use to estimate these parameters?\n\nAnswer\nBecause this is a non-time-varying study, we should use TMLE.\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nInstead of specifying an intervention using shift, we could instead supply a modified version of data to the shifted argument where the variables \\(A_t\\) are replaced with \\(A^d_t\\).\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\n\n\nQuestion\n\n\n\nHow can we interpret this result?\n\nAnswer\nIn a hypothetical world where all patients received treatment, the expected proportion of patients who receive invasive mechanical ventilation by day 15 of hospitalization is 0.2722 (95% CI: 0.24 to 0.30).\n\n\n\n\n\n\nlmtp objects\nA call to an lmtp estimator returns a list of class lmtp.\n\nValues returned in an lmtp object.\n\n\n\n\n\n\nValue\nDescription\n\n\n\n\nestimator\nThe estimator used.\n\n\ntheta\nThe estimated population LMTP effect.\n\n\nstandard_error\nThe estimated standard error of the LMTP effect.\n\n\nlow\nLower bound of the 95% confidence interval of the LMTP effect.\n\n\nhigh\nUpper bound of the 95% confidence interval of the LMTP effect.\n\n\neif\nThe estimated, un-centered, influence function of the estimate.\n\n\nshift\nThe shift function specifying the treatment policy of interest.\n\n\noutcome_reg\nAn \\(n \\times \\tau + 1\\) matrix of outcome regression predictions. The mean of the first column is used for calculating theta.\n\n\ndensity_ratios\nAn \\(n \\times \\tau\\) matrix of the estimated, non-cumulative, density ratios.\n\n\nfits_m\nA list the same length as folds, containing the fits at each time-point for each fold for the outcome regression.\n\n\nfits_r\nA list the same length as folds, containing the fits at each time-point for each fold of density ratio estimation.\n\n\noutcome_type\nThe outcome variable type.\n\n\n\nLet‚Äôs inspect some of these values.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\nLearning assessment\n\n\n\n\n\n\nProblem 1\n\n\n\nWrite a function to estimate the population mean outcome if no patients received treatment. Assign the result to an object named dont_treat.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\nSolution\n\n\nd0 &lt;- function(data, trt) {\n  rep(0, nrow(data))\n}\n\ndont_treat &lt;- lmtp_tmle(\n  data = covid, \n  trt = \"A\", \n  outcome = \"event\", \n  baseline = W, \n  outcome_type = \"binomial\", \n  shift = d0, \n  folds = 1, \n  learners_trt = \"SL.mean\", \n  learners_outcome = \"SL.glm\"\n)\n\nprint(dont_treat)\n\n\n\n\n\n\n\n\n\n\nlmtp already implements d1 and d0 as static_binary_on() and static_binary_off()!\n\n\n\n\n\nAverage treatment effect\nWith estimates of \\(\\E(Y^{\\dd_1})\\) and \\(\\E(Y^{\\dd_0})\\) we can now calculate the ATE. We‚Äôll use the function lmtp_contrast().\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nIn addition to the ATE, we can also calculate the causal risk ratio and the causal odds ratio.\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nConfirming what we already know, we‚Äôve estimated the treatment as being associated with decreased intubation or death.\n\n\n\n\n\nReferences\n\nGoyal, Parag, Justin J Choi, Laura C Pinheiro, Edward J Schenck, Ruijun Chen, Assem Jabri, Michael J Satlin, et al. 2020. ‚ÄúClinical Characteristics of Covid-19 in New York City.‚Äù New England Journal of Medicine 382 (24): 2372‚Äì74.\n\n\nWilliams, Nicholas, Michael Rosenblum, and Iv√°n Dƒ±ÃÅaz. 2022. ‚ÄúOptimising Precision and Power by Machine Learning in Randomised Trials with Ordinal and Time-to-Event Outcomes with an Application to COVID-19.‚Äù Journal of the Royal Statistical Society Series A: Statistics in Society 185 (4): 2156‚Äì78.",
    "crumbs": [
      "Home",
      "4. Estimating Effects with lmtp",
      "Static effects and the ATE"
    ]
  },
  {
    "objectID": "lmtp.html",
    "href": "lmtp.html",
    "title": "The lmtp package",
    "section": "",
    "text": "So far, we‚Äôve\n\nDefined a causal estimand for general, hypothetical interventions\nIdentified that estimand from observational data\nDiscussed 4 different estimators.\n\nIt‚Äôs now time to move on to applying this new knowledge to real data examples.\n\nExisting software and lmtp\nGeneral software for estimation of causal effects in longitudinal studies is limited:\n\nThe ipw and gfoRmula packages provide routines for estimating causal effects using inverse probability weighting (IPW) and the parametric g-formula respectively. As we already discussed, however, the validity of these methods requires making unrealistic parametric assumptions.\nThe ltmle and survtmle packages implement a doubly-robust method for estimating causal effects from longitudinal data, but these packages do not support continuous valued exposures.\n\nFirst released on CRAN in the Summer of 2021, the lmtp package is the software companion to the paper by Dƒ±ÃÅaz et al. (2023) that generalized MTPs to the longitudinal setting.\n\nWe hope to convince you that lmtp should be your default package for conducting causal analyses in R.\n\n\n\nInstallation\nFor this workshop, lmtp has already been installed with webr. However, you can install the package locally on your machine from CRAN with\n\n\ninstall.packages(\"lmtp\")\n\n\n\nPreliminaries\nBefore we move on to using lmtp, here‚Äôs general information that will be applicable across all examples:\n\nData is passed to estimators through the data argument.\nData should be in wide format with one column per variable per time point under study (i.e., there should be one column for every variable in \\(O\\)). Data may be either a data.frame or tibble but not a data.table.\nColumns do not have to be in any specific order and the data may contain variables that are not used in estimation.\nThe names of treatment variables are specified with the trt argument.\nThe names of censoring variables are specified with the cens argument.\nThe names of baseline covariates are specified with the baseline argument.\nThe names of time-varying covariates are specified with the time_vary argument.\nThe trt argument accepts either a character vector or a list of character vectors.\nThe cens and baseline arguments accept character vectors.\nThe time_vary argument accepts a list of character vectors.\nThe trt, cens, and time_vary arguments must be sorted according to the time-ordering of the model with each index containing the name (or names) of variables for the given time.\nThe outcome variable is specified with the outcome argument.\nThe outcome_type argument specifies the type of outcome. It should be set to \"continuous\" for continuous outcomes, \"binomial\" for dichotomous outcomes, and \"survival\" for time-to‚Äìevent outcomes.\nCensoring indicators should be coded using 0 and 1 where 1 indicates an observation is observed at the next time and 0 indicates loss-to-follow-up. Once an observation‚Äôs censoring status is switched to 0 it cannot change back to 1. Missing data before an observation is censored is not allowed.\nThe argument should be set to for continuous outcomes, for dichotomous outcomes, and for time-to-event outcomes.\n\n\n\nData structure examples\n\nPoint treatment\n\n\n\nAdapted from Hoffman et al., 2022.\n\n\n\n\nPoint-treatment with censoring\n\n\n\nAdapted from Hoffman et al., 2022.\n\n\n\n\nTime-varying treatment with censoring\n\n\n\nAdapted from Hoffman et al., 2022.\n\n\n\n\nPoint-treatment with survival outcome\n\n\n\nAdapted from Hoffman et al., 2022.\n\n\n\n\nTime-varying treatment with survival outcome\n\n\n\nAdapted from Hoffman et al., 2022.\n\n\n\n\n\nMachine learning ensembles\nAs was already discussed, an attractive property of multiply-robust estimators is that they can incorporate flexible machine-learning algorithms for the estimation of nuisance parameters while remaining \\(\\sqrt{n}\\)-consistent.\n\nlmtp uses the super learner algorithm for estimating these nuisance parameters.\nThe super learner algorithm is an ensemble learner than incorporates a set of candidate models through a weighted convex-combination based on cross-validation. Asymptotically, this weighted combination of models, called the meta-learner, will outperform any single one of its components.\nlmtp uses the implementation of the super learner provided by the SuperLearner package.\nThe algorithms to be used in the super learner are specified with the lrnrs_trt and lrnrs_outcome arguments.\nThe outcome variable type should guide users on selecting the appropriate candidate learners for use with the lrnrs_outcome argument.\nRegardless of whether an exposure is continuous, dichotomous, or categorical, the exposure mechanism is estimated using classification. Therefore only include candidate learners capable of binary classification with the lrnrs_trt argument.\nCandidate learners that rely on cross-validation for the tuning of hyper-parameters should support grouped data if used with lrnrs_trt. Because estimation of the treatment mechanism relies on the augmented \\(2n\\) duplicated data set, duplicated observations must be put into the same fold during sample-splitting. This is done automatically by the package.\n\n\n\n\n\n\nReferences\n\nDƒ±ÃÅaz, Iv√°n, Nicholas Williams, Katherine L Hoffman, and Edward J Schenck. 2023. ‚ÄúNonparametric Causal Effects Based on Longitudinal Modified Treatment Policies.‚Äù Journal of the American Statistical Association 118 (542): 846‚Äì57.\n\n\nVan der Laan, Mark J, Eric C Polley, and Alan E Hubbard. 2007. ‚ÄúSuper Learner.‚Äù Statistical Applications in Genetics and Molecular Biology 6 (1).\n\n\nWilliams, Nicholas, and Iv√°n Dƒ±ÃÅaz. 2023. ‚ÄúLmtp: An r Package for Estimating the Causal Effects of Modified Treatment Policies.‚Äù Observational Studies 9 (2): 103‚Äì22.",
    "crumbs": [
      "Home",
      "4. Estimating Effects with lmtp",
      "The lmtp package"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Estimating the causal effects of binary, categorical, continuous, and multivariate exposures in R",
    "section": "",
    "text": "SER 2024 - Austin, Texas\n\n\nModified treatment policies (MTPs) are a class of interventions that generalize static and dynamic interventions for categorical, continuous, and multivariate exposures. MTPs are hypothetical interventions where the post-intervention is defined as a modification of the natural value of the exposure that can depend on the unit‚Äôs history. This short course will introduce the lmtp R package for estimating the causal effects of MTPs in both point-treatment and longitudinal studies. We will discuss identification of MTPs, estimation with a targeted minimum-loss based estimator and a sequentially doubly-robust estimator, and provide guidance on estimator choice.\n\n\nLearning objectives\nBy the end of the workshop, participants will be able to:\n\nDefine MTPs intuitively and using notation, and understand how they generalize static and dynamic interventions.\nEstimate the effect of a static or dynamic intervention with for point-treatment and longitudinal studies.\nEstimate the effect of an MTP on a continuous-valued exposure with for point-treatment and longitudinal studies.\nEstimate the effect of multivariate exposures with for point-treatment and longitudinal studies.\n\n\n\nSchedule\n\n\n\nTime\nTopic\n\n\n\n\n1:00 PM - 1:15 PM\nIntroductions\n\n\n1:15 PM - 1:30 PM\nFrom observed data to causal estimands\n\n\n1:30 PM - 2:30 PM\nGeneralizing interventions using MTPs\n\n\n2:30 PM - 2:50 PM\nThe estimator landscape\n\n\n2:50 PM - 3:00 PM\nBreak\n\n\n3:00 PM - 3:15 PM\nSetting up the correct data structure\n\n\n3:15 PM - 4:45 PM\nEstimating effects using the lmtp package\n\n\n4:45 PM - 5:00 PM\nQ + A\n\n\n\n\n\nwebR\nThis workshop was prepared using Quarto and webR. The source code is available on GitHub. webR is a version of the R programming language compiled to be run directly in the browser. Using webR for this workshop avoids having to spend time setting up a computing environment and making sure workshop participants are using the same version of R and R packages.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.",
    "crumbs": [
      "Home",
      "Welcome!"
    ]
  },
  {
    "objectID": "info_tldr.html",
    "href": "info_tldr.html",
    "title": "Causal Inference in Brief",
    "section": "",
    "text": "\\[\n\\renewcommand{\\P}{\\mathsf{P}}\n\\newcommand{\\m}{\\mathsf{m}}\n\\newcommand{\\p}{\\mathsf{p}}\n\\newcommand{\\q}{\\mathsf{q}}\n\\newcommand{\\bb}{\\mathsf{b}}\n\\newcommand{\\g}{\\mathsf{g}}\n\\newcommand{\\rr}{\\mathsf{r}}\n\\newcommand{\\IF}{\\mathbb{IF}}\n\\newcommand{\\dd}{\\mathsf{d}}\n\\newcommand{\\Pn}{$\\mathsf{P}_n$}\n\\newcommand{\\E}{\\mathsf{E}}\n\\]\n\n\nA motivating example\n\n\nNotation\n\n\n\n\n\n\n\nSymbol\nDefinition\n\n\n\n\n\\(L_t\\)\nTime-varying covariates\n\n\n\\(A_t\\)\nA vector of intervention variables (i..e, treatment or exposure)\n\n\n\\(Y = L_t\\)\nAn outcome variable\n\n\n\\(C\\)\nA indicator variable that a unit is observed at the next time point\n\n\n\\(O_1, ..., O_n\\)\nA sample of i.i.d observations with \\(O = (L_1, A_1, L_2, A_2, ..., L_\\tau, A_\\tau, Y)\\)\n\n\n\\(\\bar{X}_t = (X_1, ..., X_t)\\)\nThe history of a variable up until time \\(t\\)\n\n\n\\(\\underline{X}_t = (X_t, ..., X_\\tau)\\)\nThe future of a variable, including time \\(t\\)\n\n\n\\(H_t = (\\bar{A}_{t-1}, \\bar{L}_t)\\)\nThe history of all variables up until just before \\(A_t\\)\n\n\n\\(\\g_t(a_t, h_t) = \\P(A_t = a_t \\mid H_t = h_t)\\)\nThe probability density function of \\(A_t\\) conditional on \\(H_t = h_t\\)",
    "crumbs": [
      "Home",
      "1. Introduction"
    ]
  }
]